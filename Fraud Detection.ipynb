{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Coding Challenge: Fraud detection </h1>\n",
    "    \n",
    "<h2>objectif: </h2>\n",
    "Sur la base d'un dataset de transactions, évaluer si un utilisateur va commettre une fraude ou non.\n",
    "Les données sources sont les fichiers data.csv (historique de transactions) et country.csv (correspondance entre pays et adresses IP)\n",
    "\n",
    "<h3>Approche / questions: </h3>\n",
    "    \n",
    "    1) For each user, determine her country based on the numeric IP address.\n",
    "    \n",
    "    2) Build a model to predict whether an activity is fraudulent or not. Explain how different assumptions about the cost of false positives vs false negatives would impact the model.\n",
    "\n",
    "    3) Your boss is a bit worried about using a model she doesn't understand for something as important as fraud detection. How would you explain her how the model is making the predictions? Not from a mathematical perspective (she couldn't care less about that), but from a user perspective. What kinds of users are more likely to be classified as at risk? What are their characteristics?\n",
    "\n",
    "    4) Let's say you now have this model which can be used live to predict in real time if an activity is fraudulent or not. From a product perspective, how would you use it? That is,what kind of different user experiences would you build based on the model output?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> STEP 1 => charger les données et enrichir avec le pays</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "countries = pd.read_csv(\"country.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrichissement de \"data\" avec le nom du pays correspondant a l'IP\n",
    "def country_finder(ip):\n",
    "    ip = float(ip)\n",
    "    try:\n",
    "        country = countries.loc[(ip > countries.lower_bound_ip_address) & (ip < countries.upper_bound_ip_address ),\"country\"].values[0]\n",
    "        return country\n",
    "    except:\n",
    "        return \"not_found\"\n",
    "    \n",
    "data[\"country\"] = [country_finder(r) for r in data.ip_address]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> L'ajout des pays est fait cependant on constate ci dessous que pour + de 21k enregistrements aucun pays n'a pu être déterminé. Pour l'instant ces enregistrements sont conservés, nous réévaluerons plus tard s'il est préférable de les éliminer pour optimiser le modèle </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "United States     58049\n",
       "not_found         21966\n",
       "China             12038\n",
       "Japan              7306\n",
       "United Kingdom     4490\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"country\").count()[\"user_id\"].sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2 => construction d'un modèle de prédiction</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:\n",
    "on va utiliser un algorythme de type random_forest car cet algorythme a l'avantage d'être transparent et explicite dans son mécanisme de prédiction.\n",
    "A ce stade on conserve la dataset fourni sans + d'optimisation, avec néanmoins une exclusion des colonnes ip_address (remplacée par la pays).\n",
    "On verra dans un deuxième temps si le résultat peut être améliorer avec une préparation + spécifique de la donnée.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"class\", \"ip_address\", \"signup_time\", \"purchase_time\"], axis = 1)\n",
    "y = data.loc[:,\"class\"]\n",
    "\n",
    "# le fit devrait en théorie etre fait sur la donnée de train uniquement, mais en théorie nous devrions disposer également d'une base produit complete de référence. Aussi je retiens le jeu de données complets pour le fit\n",
    "X[\"device_id\"] = le.fit_transform(X.device_id)\n",
    "X[\"source\"] = le.fit_transform(X.source)\n",
    "X[\"browser\"] = le.fit_transform(X.browser)\n",
    "X[\"sex\"] = le.fit_transform(X.sex)\n",
    "X[\"country\"] = le.fit_transform(X.country)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()               \n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as DTClass\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_fold = 5\n",
    "model = DTClass()\n",
    "scores = cross_val_score(model, X_train, y_train, cv=cv_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:\n",
    "l'entrainement du modèle sur les données brutes fournit un résultat de prédiction juste à environ 89%, comme on peut le voir sur le graph ci dessous*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2c2e1780>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACa9JREFUeJzt3W+oXPldx/HPd5NdNpvtupYsi95Ub8OVapHSLqFUKkVaKXWV+lRLn7UUpFwiFcVSKOpjEZf7QFgqWvxD0fUPUhZRUJ8UURObrVsTy1i2bdI/m7po/2R1dfvzwZxtQ1rIvck9M99kXi8YMjn3zJzfN3N558yZXFJjjACwfnetewEALAkyQBOCDNCEIAM0IcgATQgyQBOCDNCEIAM0IcgATRw9yM4nTpwY29vbMy0F4M507ty5L48xHrrRfgcK8vb2ds6ePXvzqwLYQFX1mf3s55IFQBOCDNCEIAM0IcgATQgyQBOCDNCEIAM0IcgATQgyQBOCDNCEIAM0IcgATQgyQBOCDNCEIAM0IcgATQgyQBOCDNCEIAM0caD/Uw9uN3t7e1ksFutexka5fPlykmRra+vAj93Z2cnu7u5hL+m2Icjc0RaLRc4/fSEv3vfydS9lYxy5+l9Jki/+z8HycuTqc3Ms57YiyNzxXrzv5Xn+Bx9d9zI2xrGLTybJgf/MX3rcJnMNGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaCJlQR5b28ve3t7qzgUwKFaZb+OruIgi8ViFYcBOHSr7JdLFgBNCDJAE4IM0IQgAzQhyABNCDJAE4IM0IQgAzQhyABNCDJAE4IM0IQgAzQhyABNCDJAE4IM0IQgAzQhyABNCDJAE4IM0IQgAzQhyABNCDJAE4IM0IQgAzQhyABNCDJAE4IM0IQgAzQhyABNCDJAE4IM0IQgAzQhyABNCDJAE4IM0IQgAzQhyABNCDJAE4IM0IQgAzQhyABNHF3FQS5fvpznn38+Z86cWcXh4JsWi0XuemGsexnsw13//ZUsFl9t14nFYpFjx46t5Fg3PEOuqvdU1dmqOnvlypVVrAlgI93wDHmM8XiSx5Pk9OnTN3WqsbW1lSR57LHHbubhcNPOnDmTc5/+0rqXwT58494HsnPq4XadWOUZu2vIAE0IMkATggzQhCADNCHIAE0IMkATggzQhCADNCHIAE0IMkATggzQhCADNCHIAE0IMkATggzQhCADNCHIAE0IMkATggzQhCADNCHIAE0IMkATggzQhCADNCHIAE0IMkATggzQhCADNCHIAE0IMkATggzQhCADNCHIAE0IMkATggzQhCADNCHIAE0IMkATggzQhCADNCHIAE0IMkATR1dxkJ2dnVUcBuDQrbJfKwny7u7uKg4DcOhW2S+XLACaEGSAJgQZoAlBBmhCkAGaEGSAJgQZoAlBBmhCkAGaEGSAJgQZoAlBBmhCkAGaEGSAJgQZoAlBBmhCkAGaEGSAJgQZoAlBBmhCkAGaEGSAJgQZoAlBBmhCkAGaEGSAJgQZoAlBBmhCkAGaEGSAJgQZoAlBBmhCkAGaEGSAJgQZoAlBBmhCkAGaEGSAJgQZoAlBBmji6LoXAHM7cvW5HLv45LqXsTGOXP2PJDnwn/mRq88leXiGFd0+BJk72s7OzrqXsHEuX/6/JMnW1kHj+vDGv16CzB1td3d33UuAfXMNGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmhBkgCZqjLH/nauuJPnMfMvJiSRfnvH5uzL3ZtnUuZPNnf37xxgP3WinAwV5blV1doxxet3rWDVzb5ZNnTvZ7Nn3wyULgCYEGaCJbkF+fN0LWBNzb5ZNnTvZ7NlvqNU1ZIBN1u0MGWBjzRbkqnpbVf1bVS2q6pe/w9e/r6r+tqo+XlWfqKpHp+13V9WHq+pfqupCVb1/2v6Kaf8LVfXJqjoz19pvxQxz31tV/1hVT01z/+qqZ9qvw579mscdmR7z0VXNchBzzF1Vz0zbz1fV2VXOs18zzf1gVT1RVRenr/3IKmdauzHGod+SHEny70lOJbknyVNJXn3dPo8n+bnp/quTPDPdf0eSj0z370vyTJLtJN+T5JFp+8uSfOr651z3baa5K8n90/a7k/xDkjese9ZVzH7N496X5A+TfHTdc65q7un+iXXPt4a5P5zk3dP9e5I8uO5ZV3mb6wz59UkWY4xPjzFeSPKRJD993T4jyQPT/e9K8vlrth+vqqNJjiV5IclXxhhfGGP8c5KMMb6a5EKSrZnWf7PmmHuMMb427XP3dOt44f/QZ0+SqjqZ5CeTfGje5d+0Wea+DRz63FX1QJI3JfntJBljvDDG+M95x+hlriBvJfncNb+/lG+P568keWdVXUryZJLdafsTSb6e5AtJPpvk18cYz137wKraTvK6LM8WO5ll7ukt+/kkzyb56zFGt7mT+V7z30zyS0m+Mc+yb9lcc48kf1VV56rqPTOt/VbMMfepJFeS/M50meNDVXV8vhH6mSvI9R22XX9W97NJfneMcTLJo0l+r6ruyvJv3heTfG+SVyb5hao69c0nrro/yZ8k+fkxRreziVnmHmO8OMZ4bZKTSV5fVT881wC34NBnr6qfSvLsGOPcjOu+VXN9r79xjPFIkp9I8t6qetMsq795c8x9NMkjSX5rjPG6LKP9bdem72RzBflSkldc8/uT+dbblZe8K8kfJckY4++T3Jvlz7m/I8lfjjH+d4zxbJKPJTmdLD8MyDLGfzDG+NOZ1n4rZpn7JdPbt79L8rY5Fn+L5pj9jUneXlXPZPmW+M1V9ftzDnETZnnNxxifn359NsmfZRmxTuaY+1KSS9e8A3wiy0BvjLmC/E9JfqCqXllV9yT5mSR/cd0+n03yliSpqh/K8sW6Mm1/cy0dT/KGJBerqrK8tnRhjPEbM637Vs0x90NV9eC0/7EkP57k4kqmOZhDn32M8f4xxskxxvb0fH8zxnjnasbZtzle8+NV9bJp/+NJ3prk6ZVMs39zvN5fTPK5qnrV9Pi3JPnX+UdpZK5PC7N8i/KpLD+J/cC07deSvH1861PXj2X56ez5JG+dtt+f5I+TfDLLF+MXp+0/muVbok9M+59P8ui6PxVdwdyvSfLxae6nk3xw3TOuavbrnvvH0vBfWcz0mp+a9n1q+toH1j3jql7vJK9Ncnb6fv/zJN+97jlXefOTegBN+Ek9gCYEGaAJQQZoQpABmhBkgCYEGaAJQQZoQpABmvh/YBjkFeWKBSEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*on peut par ailleurs visualiser le chemin emprunté par l'arbre pour arriver a ces prédictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' a completer\\n\\nfrom graphviz import Source\\nfrom sklearn import tree\\nfrom IPython.display import SVG\\n\\n# application de l\\'encodate variable au jeu de test\\n\\nX_test[\"device_id\"] = le.transform(X_test.device_id)\\nX_train[\"source\"] = le.transform(X_test.source)\\nX_train[\"browser\"] = le.transform(X_test.browser)\\nX_train[\"sex\"] = le.transform(X_test.sex)\\nX_train[\"country\"] = le.transform(X_test.country)\\n\\n\\ngraph = Source(tree.export_graphviz(model, out_file=None, feature_names=X.columns))\\nSVG(graph.pipe(format=\\'svg\\'))\\n'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' a completer\n",
    "\n",
    "from graphviz import Source\n",
    "from sklearn import tree\n",
    "from IPython.display import SVG\n",
    "\n",
    "# application de l'encodate variable au jeu de test\n",
    "\n",
    "X_test[\"device_id\"] = le.transform(X_test.device_id)\n",
    "X_train[\"source\"] = le.transform(X_test.source)\n",
    "X_train[\"browser\"] = le.transform(X_test.browser)\n",
    "X_train[\"sex\"] = le.transform(X_test.sex)\n",
    "X_train[\"country\"] = le.transform(X_test.country)\n",
    "\n",
    "\n",
    "graph = Source(tree.export_graphviz(model, out_file=None, feature_names=X.columns))\n",
    "SVG(graph.pipe(format='svg'))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:\n",
    "on teste ce modèle sur un réel jeu de test*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31775,  2495],\n",
       "       [ 1744,  1764]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
